---
title: "Machine Learning Model"
description: |
  Linear Regression

date: "`r Sys.Date()`"
output: distill::distill_article
---
Linear regression is simply using various types of data to determine which one is the best one to use when making predictions. Then it uses a graph to determine how well the prediction is.  Finally, it draws a line through a scattergraph so you can see how close the data gets to the line. This can be useful in accounting during an audit. It can predict which areas will need the most areas of audit.

**Change the p=.6 to p=.75 in the Data Pre-Processing section. How did the classification results change?**

```{r, echo=TRUE, message=FALSE}
library(tidyverse)
library(caret)
#change the p=.6 to p=.75
#what does createDataPartition do?
#run the following code: ?createDataPartition

#this creates an index of rows in include in the training
#literally lists the rows to keep
trainIndex <- createDataPartition(iris$Species, p = .75, list = FALSE, times = 1)

#rows to keep
knitr::kable(trainIndex)%>%
  kableExtra::kable_styling("striped")%>%
  kableExtra::scroll_box(width = "100%",height="200px")

#grab the data
#take these rows
irisTrain <- iris[ trainIndex,]
#don't take these rows
irisTest  <- iris[-trainIndex,]

#we now have training and testing data sets


```

```{r, echo=TRUE}
#for the algorithm we are using it requires that we standardize

#center= subtract the means and 
#scale = divide by standard deviation
#?preProcess sets the conversion up 
preProcValues <- preProcess(irisTrain, method = c("center", "scale"))

preProcValues
```

```{r, echo=TRUE}
#this predict actual change the variables
trainTransformed <- predict(preProcValues, irisTrain)
#repeat for testing
preProcValues <- preProcess(irisTest, method = c("center", "scale"))
testTransformed <- predict(preProcValues, irisTest)

```

```{r, echo=TRUE}
#data is split and standardized
#time to run the model
#fit knn

#use train function and set up the equation
knn_fit<-train(Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
              #data we are using
              data=trainTransformed,
              #algorithm we are using
              method="knn",
              #the hyperparameter or tuning parameter is the
              #number of neighbors...here we set it to 5
              tuneGrid=data.frame(k=5))

#this is the object that holds the model
knn_fit

#predict on the test set
knn_pred<-predict(knn_fit,testTransformed)

#confusion matrix gives us the results
confusionMatrix(knn_pred,testTransformed$Species)
```

By comparing the variances we see that as the number of components increase each individual component's explained variance drops.




